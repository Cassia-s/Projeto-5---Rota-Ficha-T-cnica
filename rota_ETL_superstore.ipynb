{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Instalação das bibliotecas"
      ],
      "metadata": {
        "id": "fNHnyB6ZP8M_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar pandas\n",
        "!pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i07CKq1cOqZQ",
        "outputId": "cc056c3b-bddf-4898-c11a-fb457d6b92d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Importe a biblioteca"
      ],
      "metadata": {
        "id": "sXCSAEoYVj1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "cMopCesFVoBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definir a URL e fazer a requisição"
      ],
      "metadata": {
        "id": "puMkgguzO_Ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# URL da página da Wikipédia\n",
        "url = 'https://pt.wikipedia.org/wiki/Fortune_Global_500'\n",
        "\n",
        "# Usar pandas para ler todas as tabelas na página\n",
        "try:\n",
        "    tabelas_html = pd.read_html(url)\n",
        "\n",
        "    # A tabela com as empresas é a segunda na página (índice 1).\n",
        "    # Você pode verificar isso inspecionando a página.\n",
        "    df_concorrentes = tabelas_html[1]\n",
        "\n",
        "    print('Web scraping realizado com sucesso!')\n",
        "    print('\\nPrimeiras 5 linhas da tabela de concorrentes:')\n",
        "    print(df_concorrentes.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro ao tentar realizar o web scraping: {e}\")\n",
        "    print(\"Verifique a URL e sua conexão com a internet.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9XuoAOLO13n",
        "outputId": "3f82f441-a4a4-4ac2-84d4-348aced1e039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Web scraping realizado com sucesso!\n",
            "\n",
            "Primeiras 5 linhas da tabela de concorrentes:\n",
            "   Classificação            País  Companhias\n",
            "0              1  Estados Unidos         128\n",
            "1              2           China          98\n",
            "2              3           Japão          54\n",
            "3              4          França          31\n",
            "4              5     Reino Unido          29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Salvar o arquivo"
      ],
      "metadata": {
        "id": "48daeS6NV8Ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_concorrentes.to_csv('concorrentes.csv', index=False)"
      ],
      "metadata": {
        "id": "hoypatdOV8dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encontrar e extrair a tabela desejada"
      ],
      "metadata": {
        "id": "9HCofWNGRXsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# Passo de Web Scraping usando BeautifulSoup\n",
        "# ===============================================\n",
        "\n",
        "# 1. Instalar as bibliotecas (se necessário)\n",
        "!pip install requests beautifulsoup4 pandas\n",
        "\n",
        "# 2. Importar as bibliotecas\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# 3. Definir a URL\n",
        "url = 'https://pt.wikipedia.org/wiki/Fortune_Global_500'\n",
        "\n",
        "# 4. Fazer a requisição HTTP para obter o conteúdo da página\n",
        "try:\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status() # Lança um erro para status de erro (4xx ou 5xx)\n",
        "\n",
        "    # 5. Criar um objeto BeautifulSoup para analisar o HTML\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # 6. Encontrar a tabela desejada (por classe ou outro identificador)\n",
        "    # A classe 'wikitable' é um bom identificador na Wikipedia\n",
        "    tabelas_wikitable = soup.find_all('table', {'class': 'wikitable'})\n",
        "\n",
        "    # Vamos assumir que a tabela que queremos é a segunda da página (índice 1)\n",
        "    tabela_empresas = tabelas_wikitable[1]\n",
        "\n",
        "    # 7. Extrair os dados da tabela e criar um DataFrame\n",
        "    # Este é um método simplificado para demonstrar o processo\n",
        "    dados_empresas = []\n",
        "    for row in tabela_empresas.find_all('tr'):\n",
        "        cols = row.find_all(['th', 'td'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        dados_empresas.append(cols)\n",
        "\n",
        "    # 8. Criar o DataFrame\n",
        "    # A primeira linha é o cabeçalho\n",
        "    headers = dados_empresas[0]\n",
        "    df_concorrentes = pd.DataFrame(dados_empresas[1:], columns=headers)\n",
        "\n",
        "    print('Web scraping realizado com sucesso!')\n",
        "    print('\\nPrimeiras 5 linhas da tabela de concorrentes:')\n",
        "    print(df_concorrentes.head())\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Ocorreu um erro na requisição: {e}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro no web scraping: {e}\")"
      ],
      "metadata": {
        "id": "lcRtdqywRW0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ed8a656-7a75-4450-f74e-012e1dc4b67c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.7.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Web scraping realizado com sucesso!\n",
            "\n",
            "Primeiras 5 linhas da tabela de concorrentes:\n",
            "  Classificação            País Companhias\n",
            "0             1  Estados Unidos        128\n",
            "1             2           China         98\n",
            "2             3           Japão         54\n",
            "3             4          França         31\n",
            "4             5     Reino Unido         29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criar um DataFrame com os dados"
      ],
      "metadata": {
        "id": "NxTUS1pwRpk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar o DataFrame\n",
        "df_multinacionais = pd.DataFrame(dados_empresas, columns=headers)\n",
        "\n",
        "# Exibir as primeiras linhas do DataFrame para verificar o resultado\n",
        "print(df_multinacionais.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYU1WK8XRqHd",
        "outputId": "86402878-ffe0-4b4a-d5d5-14e8d64d457f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Classificação            País  Companhias\n",
            "0  Classificação            País  Companhias\n",
            "1              1  Estados Unidos         128\n",
            "2              2           China          98\n",
            "3              3           Japão          54\n",
            "4              4          França          31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 2: Extrair e carregar dados de concorrentes"
      ],
      "metadata": {
        "id": "e-6WsIrcdjxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# URL de exportação da sua planilha de concorrentes como CSV\n",
        "url_concorrentes = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRbKOAov8N5kL7rhk5xb6so7_fb9mYw-Y4gDwbY2vRb_1VN1y2uVz1h_yqPxLR3gO_1GRvLiQzIY9at/pub?output=csv'\n",
        "\n",
        "try:\n",
        "    df_concorrentes = pd.read_csv(url_concorrentes)\n",
        "    print(\"\\nDataFrame de concorrentes carregado com sucesso:\")\n",
        "    print(df_concorrentes.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nOcorreu um erro ao ler a planilha online: {e}\")\n",
        "    print(\"Verifique se o URL está correto e se a planilha está pública.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBGrUs3Fdg61",
        "outputId": "94749e40-7833-4267-c25f-edbd8a447dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame de concorrentes carregado com sucesso:\n",
            "   row_id         category sub_category      segment  region  country state  \\\n",
            "0   43411  office supplies          art  home office  africa  nigeria  abia   \n",
            "1   41699  office supplies      storage     consumer  africa  nigeria  abia   \n",
            "2   41698  office supplies          art     consumer  africa  nigeria  abia   \n",
            "3   41700  office supplies    envelopes     consumer  africa  nigeria  abia   \n",
            "4   48201  office supplies          art     consumer  africa  nigeria  abia   \n",
            "\n",
            "  city  market market2  ...                          product_name  order_date  \\\n",
            "0  aba  africa  africa  ...  Boston Pencil Sharpener, Water Color  16/04/2011   \n",
            "1  aba  africa  africa  ...                 Smead Box, Industrial  04/09/2012   \n",
            "2  aba  africa  africa  ...       Binney & Smith Pens, Easy-Erase  04/09/2012   \n",
            "3  aba  africa  africa  ...          Jiffy Mailers, Security-Tint  04/09/2012   \n",
            "4  aba  africa  africa  ...           Boston Markers, Water Color  13/09/2012   \n",
            "\n",
            "    ship_date  year weeknum sales discount   profit quantity  shipping_cost  \n",
            "0  21/04/2011  2011      16   135      0,7  -90,174       14          10,61  \n",
            "1  08/09/2012  2012      36     7      0,7   -13,95        2           0,58  \n",
            "2  08/09/2012  2012      36     7      0,7  -17,094        2           0,41  \n",
            "3  08/09/2012  2012      36    12      0,7  -12,669        1            0,3  \n",
            "4  18/09/2012  2012      37    18      0,7   -41,37        2           2,51  \n",
            "\n",
            "[5 rows x 26 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 1.1: Limpeza e Transformação em df_superstore"
      ],
      "metadata": {
        "id": "VJHuc4Xber9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Padronizar nomes de colunas (se necessário)\n",
        "df_concorrentes.columns = [col.lower().replace(' ', '_') for col in df_concorrentes.columns]\n",
        "\n",
        "# 2. Converter tipos de dados\n",
        "# Datas\n",
        "df_concorrentes['order_date'] = pd.to_datetime(df_concorrentes['order_date'])\n",
        "df_concorrentes['ship_date'] = pd.to_datetime(df_concorrentes['ship_date'])\n",
        "\n",
        "# Numéricos\n",
        "df_concorrentes['sales'] = pd.to_numeric(df_concorrentes['sales'], errors='coerce')\n",
        "df_concorrentes['discount'] = pd.to_numeric(df_concorrentes['discount'], errors='coerce')\n",
        "df_concorrentes['profit'] = pd.to_numeric(df_concorrentes['profit'], errors='coerce')\n",
        "df_concorrentes['shipping_cost'] = pd.to_numeric(df_concorrentes['shipping_cost'], errors='coerce')\n",
        "df_concorrentes['quantity'] = pd.to_numeric(df_concorrentes['quantity'], errors='coerce').astype('Int64')\n",
        "df_concorrentes['year'] = pd.to_numeric(df_concorrentes['year'], errors='coerce').astype('Int64')\n",
        "df_concorrentes['weeknum'] = pd.to_numeric(df_concorrentes['weeknum'], errors='coerce').astype('Int64')\n",
        "\n",
        "# 3. Padronizar strings\n",
        "colunas_texto = ['category', 'city', 'country', 'customer_id', 'customer_name', 'market',\n",
        "                 'order_id', 'order_priority', 'product_id', 'product_name', 'region',\n",
        "                 'segment', 'ship_mode', 'state', 'sub_category', 'market2']\n",
        "for col in colunas_texto:\n",
        "    df_concorrentes[col] = df_concorrentes[col].str.lower()\n",
        "\n",
        "print(\"\\nTransformação de df_concorrentes concluída!\")\n",
        "print(df_concorrentes.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3WHOyJMepnU",
        "outputId": "dded19af-760f-4757-ffb2-8775c0783595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Transformação de df_concorrentes concluída!\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 500 entries, 0 to 499\n",
            "Data columns (total 26 columns):\n",
            " #   Column          Non-Null Count  Dtype         \n",
            "---  ------          --------------  -----         \n",
            " 0   row_id          500 non-null    int64         \n",
            " 1   category        500 non-null    object        \n",
            " 2   sub_category    500 non-null    object        \n",
            " 3   segment         500 non-null    object        \n",
            " 4   region          500 non-null    object        \n",
            " 5   country         500 non-null    object        \n",
            " 6   state           500 non-null    object        \n",
            " 7   city            500 non-null    object        \n",
            " 8   market          500 non-null    object        \n",
            " 9   market2         500 non-null    object        \n",
            " 10  order_priority  500 non-null    object        \n",
            " 11  ship_mode       500 non-null    object        \n",
            " 12  customer_id     500 non-null    object        \n",
            " 13  customer_name   500 non-null    object        \n",
            " 14  order_id        500 non-null    object        \n",
            " 15  product_id      500 non-null    object        \n",
            " 16  product_name    500 non-null    object        \n",
            " 17  order_date      500 non-null    datetime64[ns]\n",
            " 18  ship_date       500 non-null    datetime64[ns]\n",
            " 19  year            500 non-null    Int64         \n",
            " 20  weeknum         500 non-null    Int64         \n",
            " 21  sales           500 non-null    int64         \n",
            " 22  discount        369 non-null    float64       \n",
            " 23  profit          13 non-null     float64       \n",
            " 24  quantity        500 non-null    Int64         \n",
            " 25  shipping_cost   4 non-null      float64       \n",
            "dtypes: Int64(3), datetime64[ns](2), float64(3), int64(2), object(16)\n",
            "memory usage: 103.2+ KB\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-180397711.py:6: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  df_concorrentes['order_date'] = pd.to_datetime(df_concorrentes['order_date'])\n",
            "/tmp/ipython-input-180397711.py:7: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  df_concorrentes['ship_date'] = pd.to_datetime(df_concorrentes['ship_date'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 2.1: Limpeza e Transformação em df_concorrentes"
      ],
      "metadata": {
        "id": "0zamHJcxe-kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Padronizar nomes das colunas\n",
        "# Supondo que as colunas sejam: 'Rank', 'Company', 'Country', 'Industry', 'Revenue', etc.\n",
        "df_concorrentes.columns = [col.lower().replace(' ', '_') for col in df_concorrentes.columns]\n",
        "\n",
        "# 2. Padronizar strings para facilitar análises futuras\n",
        "colunas_texto_concorrentes = ['company', 'country', 'industry'] # Ajuste com base nas suas colunas\n",
        "for col in colunas_texto_concorrentes:\n",
        "    if col in df_concorrentes.columns:\n",
        "        df_concorrentes[col] = df_concorrentes[col].str.lower()\n",
        "\n",
        "print(\"\\nTransformação de df_concorrentes concluída!\")\n",
        "print(df_concorrentes.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gk95_Ka2e70F",
        "outputId": "0159bfc9-9ef5-4b5a-fcfc-86016c6cc38a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Transformação de df_concorrentes concluída!\n",
            "   row_id         category sub_category      segment  region  country state  \\\n",
            "0   43411  office supplies          art  home office  africa  nigeria  abia   \n",
            "1   41699  office supplies      storage     consumer  africa  nigeria  abia   \n",
            "2   41698  office supplies          art     consumer  africa  nigeria  abia   \n",
            "3   41700  office supplies    envelopes     consumer  africa  nigeria  abia   \n",
            "4   48201  office supplies          art     consumer  africa  nigeria  abia   \n",
            "\n",
            "  city  market market2  ...                          product_name order_date  \\\n",
            "0  aba  africa  africa  ...  boston pencil sharpener, water color 2011-04-16   \n",
            "1  aba  africa  africa  ...                 smead box, industrial 2012-09-04   \n",
            "2  aba  africa  africa  ...       binney & smith pens, easy-erase 2012-09-04   \n",
            "3  aba  africa  africa  ...          jiffy mailers, security-tint 2012-09-04   \n",
            "4  aba  africa  africa  ...           boston markers, water color 2012-09-13   \n",
            "\n",
            "   ship_date  year weeknum sales discount profit quantity  shipping_cost  \n",
            "0 2011-04-21  2011      16   135      NaN    NaN       14            NaN  \n",
            "1 2012-09-08  2012      36     7      NaN    NaN        2            NaN  \n",
            "2 2012-09-08  2012      36     7      NaN    NaN        2            NaN  \n",
            "3 2012-09-08  2012      36    12      NaN    NaN        1            NaN  \n",
            "4 2012-09-18  2012      37    18      NaN    NaN        2            NaN  \n",
            "\n",
            "[5 rows x 26 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo: Criar a dimensão de Localização"
      ],
      "metadata": {
        "id": "pW5Xk2kALeyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import hashlib\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "import pandas_gbq\n",
        "\n",
        "# ===============================================\n",
        "# EXTRAÇÃO: Carregar os dados\n",
        "# ===============================================\n",
        "try:\n",
        "    df_superstore = pd.read_csv('superstore.csv', encoding='utf-8')\n",
        "    print(\"Arquivo superstore.csv carregado com sucesso!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Erro: O arquivo 'superstore.csv' não foi encontrado. Por favor, faça o upload do arquivo.\")\n",
        "    df_superstore = pd.DataFrame() # DataFrame vazio para evitar erros\n",
        "\n",
        "url_concorrentes = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRbKOAov8N5kL7rhk5xb6so7_fb9mYw-Y4gDwbY2vRb_1VN1y2uVz1h_yqPxLR3gO_1GRvLiQzIY9at/pub?output=csv'\n",
        "try:\n",
        "    df_concorrentes = pd.read_csv(url_concorrentes)\n",
        "    print(\"\\nDataFrame de concorrentes carregado com sucesso!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nOcorreu um erro ao ler a planilha online: {e}\")\n",
        "    df_concorrentes = pd.DataFrame()\n",
        "\n",
        "# ===============================================\n",
        "# TRANSFORMAÇÃO: Modelagem Dimensional Star Schema\n",
        "# ===============================================\n",
        "if not df_superstore.empty:\n",
        "    # Padronizar nomes de colunas e converter tipos\n",
        "    df_superstore.columns = [col.lower().replace(' ', '_') for col in df_superstore.columns]\n",
        "\n",
        "    # Correção do aviso de data\n",
        "    df_superstore['order_date'] = pd.to_datetime(df_superstore['order_date'], format='%d/%m/%Y', errors='coerce')\n",
        "    df_superstore['ship_date'] = pd.to_datetime(df_superstore['ship_date'], format='%d/%m/%Y', errors='coerce')\n",
        "\n",
        "    # Função para gerar chaves substitutas de forma consistente\n",
        "    def generate_surrogate_key(df, columns):\n",
        "        df['join_key'] = df[columns].astype(str).sum(axis=1)\n",
        "        df['surrogate_key'] = df['join_key'].apply(lambda x: hashlib.sha256(x.encode()).hexdigest())\n",
        "        df.drop(columns=['join_key'], inplace=True)\n",
        "        return df\n",
        "\n",
        "    # 1. Criar a dimensão de Localização (dim_location)\n",
        "    dim_location_df = df_superstore[['country', 'state', 'city', 'region', 'market', 'market2']].drop_duplicates().reset_index(drop=True)\n",
        "    dim_location_df = generate_surrogate_key(dim_location_df, ['country', 'state', 'city', 'region', 'market', 'market2'])\n",
        "    dim_location_df.rename(columns={'surrogate_key': 'location_id'}, inplace=True)\n",
        "    print(\"\\nDimensão de Localização criada com sucesso!\")\n",
        "\n",
        "    # 2. Criar a dimensão de Clientes (dim_customer)\n",
        "    dim_customer_df = df_superstore[['customer_id', 'customer_name', 'segment']].drop_duplicates().reset_index(drop=True)\n",
        "    dim_customer_df.rename(columns={'customer_id': 'customer_natural_key'}, inplace=True)\n",
        "    dim_customer_df['customer_id'] = generate_surrogate_key(dim_customer_df, ['customer_natural_key'])['surrogate_key']\n",
        "    print(\"Dimensão de Clientes criada com sucesso!\")\n",
        "\n",
        "    # 3. Criar a dimensão de Produtos (dim_product)\n",
        "    dim_product_df = df_superstore[['product_id', 'product_name', 'category', 'sub_category']].drop_duplicates().reset_index(drop=True)\n",
        "    dim_product_df.rename(columns={'product_id': 'product_natural_key'}, inplace=True)\n",
        "    dim_product_df['product_id'] = generate_surrogate_key(dim_product_df, ['product_natural_key'])['surrogate_key']\n",
        "    print(\"Dimensão de Produtos criada com sucesso!\")\n",
        "\n",
        "    # 4. Criar a dimensão de Pedidos (dim_order)\n",
        "    dim_order_df = df_superstore[['order_id', 'ship_mode', 'order_priority']].drop_duplicates(subset=['order_id']).reset_index(drop=True)\n",
        "    dim_order_df.rename(columns={'order_id': 'order_natural_key'}, inplace=True)\n",
        "    dim_order_df['order_id'] = generate_surrogate_key(dim_order_df, ['order_natural_key'])['surrogate_key']\n",
        "    print(\"Dimensão de Pedidos criada com sucesso!\")\n",
        "\n",
        "    # 5. Criar a Tabela de Fatos (fact_sales)\n",
        "    df_temp = pd.merge(df_superstore, dim_location_df, on=['country', 'state', 'city', 'region', 'market', 'market2'], how='left')\n",
        "    df_temp['customer_id_surrogate'] = df_temp['customer_id'].map(dim_customer_df.set_index('customer_natural_key')['customer_id'])\n",
        "    df_temp['product_id_surrogate'] = df_temp['product_id'].map(dim_product_df.set_index('product_natural_key')['product_id'])\n",
        "    df_temp['order_id_surrogate'] = df_temp['order_id'].map(dim_order_df.set_index('order_natural_key')['order_id'])\n",
        "\n",
        "    fact_sales_df = df_temp[[\n",
        "        'order_date',\n",
        "        'ship_date',\n",
        "        'sales',\n",
        "        'profit',\n",
        "        'quantity',\n",
        "        'discount',\n",
        "        'shipping_cost',\n",
        "        'customer_id_surrogate',\n",
        "        'product_id_surrogate',\n",
        "        'order_id_surrogate',\n",
        "        'location_id',\n",
        "    ]].copy()\n",
        "\n",
        "    fact_sales_df.rename(columns={\n",
        "        'customer_id_surrogate': 'customer_id',\n",
        "        'product_id_surrogate': 'product_id',\n",
        "        'order_id_surrogate': 'order_id'\n",
        "    }, inplace=True)\n",
        "\n",
        "    print(\"\\nModelo Star Schema criado com sucesso! As tabelas de dimensão e fatos estão prontas.\")\n",
        "\n",
        "# ===============================================\n",
        "# TRANSFORMAÇÃO: Concorrentes\n",
        "# ===============================================\n",
        "if not df_concorrentes.empty:\n",
        "    df_concorrentes.columns = [col.lower().replace(' ', '_') for col in df_concorrentes.columns]\n",
        "    print(\"\\nDataFrame de concorrentes padronizado.\")\n",
        "    df_concorrentes['concorrente_id'] = df_concorrentes.index + 1\n",
        "    print(\"\\nDimensão de Concorrentes criada com sucesso!\")\n",
        "\n",
        "# ===============================================\n",
        "# CARREGAMENTO (LOAD) para o BigQuery\n",
        "# Descomente e substitua o 'seu-id-do-projeto'\n",
        "# ===============================================\n",
        "# auth.authenticate_user()\n",
        "# projeto_id = 'seu-id-do-projeto'\n",
        "# print(\"\\nIniciando o carregamento para o BigQuery...\")\n",
        "\n",
        "# if not fact_sales_df.empty:\n",
        "#     pandas_gbq.to_gbq(fact_sales_df, f'{projeto_id}.superstore.fact_sales', project_id=projeto_id, if_exists='replace')\n",
        "#     print(\"Tabela fact_sales carregada.\")\n",
        "\n",
        "# if not dim_location_df.empty:\n",
        "#     pandas_gbq.to_gbq(dim_location_df, f'{projeto_id}.superstore.dim_location', project_id=projeto_id, if_exists='replace')\n",
        "#     print(\"Tabela dim_location carregada.\")\n",
        "\n",
        "# if not dim_customer_df.empty:\n",
        "#     pandas_gbq.to_gbq(dim_customer_df, f'{projeto_id}.superstore.dim_customer', project_id=projeto_id, if_exists='replace')\n",
        "#     print(\"Tabela dim_customer carregada.\")\n",
        "\n",
        "# if not dim_product_df.empty:\n",
        "#     pandas_gbq.to_gbq(dim_product_df, f'{projeto_id}.superstore.dim_product', project_id=projeto_id, if_exists='replace')\n",
        "#     print(\"Tabela dim_product carregada.\")\n",
        "\n",
        "# if not dim_order_df.empty:\n",
        "#     pandas_gbq.to_gbq(dim_order_df, f'{projeto_id}.superstore.dim_order', project_id=projeto_id, if_exists='replace')\n",
        "#     print(\"Tabela dim_order carregada.\")\n",
        "\n",
        "# if not df_concorrentes.empty:\n",
        "#     pandas_gbq.to_gbq(df_concorrentes, f'{projeto_id}.superstore.dim_concorrentes', project_id=projeto_id, if_exists='replace')\n",
        "#     print(\"Tabela dim_concorrentes carregada.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckqTQLV-UUtd",
        "outputId": "40c82ea7-dcc6-49c4-886c-fd86faf9c6d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo superstore.csv carregado com sucesso!\n",
            "\n",
            "DataFrame de concorrentes carregado com sucesso!\n",
            "\n",
            "Dimensão de Localização criada com sucesso!\n",
            "Dimensão de Clientes criada com sucesso!\n",
            "Dimensão de Produtos criada com sucesso!\n",
            "Dimensão de Pedidos criada com sucesso!\n",
            "\n",
            "Modelo Star Schema criado com sucesso! As tabelas de dimensão e fatos estão prontas.\n",
            "\n",
            "DataFrame de concorrentes padronizado.\n",
            "\n",
            "Dimensão de Concorrentes criada com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 3: Carregamento (Load) para o BigQuery"
      ],
      "metadata": {
        "id": "zLyzP8I2fxJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# ===============================================\n",
        "# Passo 1: Extração e Transformação em df_superstore\n",
        "# ===============================================\n",
        "# Carregar o arquivo CSV (substitua 'superstore.csv' pelo seu arquivo se necessário)\n",
        "# df_superstore = pd.read_csv('superstore.csv')\n",
        "\n",
        "# Para este exemplo, vamos supor que o arquivo já está carregado\n",
        "# Se você tiver o arquivo, use a linha acima.\n",
        "# Para o nosso exemplo, vamos criar um DataFrame fictício\n",
        "data = {'col1': [1, 2, 3], 'col2': ['a', 'b', 'c']}\n",
        "df_superstore = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "# 1. Padronizar nomes de colunas (se necessário)\n",
        "df_superstore.columns = [col.lower().replace(' ', '_') for col in df_superstore.columns]\n",
        "\n",
        "# ... Adicione aqui todas as suas transformações para df_superstore ...\n",
        "\n",
        "print(\"DataFrame de superstore pronto para o carregamento.\")\n",
        "\n",
        "# ===============================================\n",
        "# Passo 2: Extração e Transformação em df_concorrentes\n",
        "# ===============================================\n",
        "# URL de exportação da sua planilha de concorrentes como CSV\n",
        "url_concorrentes = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRbKOAov8N5kL7rhk5xb6so7_fb9mYw-Y4gDwbY2vRb_1VN1y2uVz1h_yqPxLR3gO_1GRvLiQzIY9at/pub?output=csv'\n",
        "\n",
        "try:\n",
        "    df_concorrentes = pd.read_csv(url_concorrentes)\n",
        "    df_concorrentes.columns = [col.lower().replace(' ', '_') for col in df_concorrentes.columns]\n",
        "    # ... Adicione aqui suas transformações para df_concorrentes ...\n",
        "    print(\"DataFrame de concorrentes pronto para o carregamento.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nOcorreu um erro ao ler a planilha online: {e}\")\n",
        "    df_concorrentes = pd.DataFrame() # Cria um DataFrame vazio para evitar erro no passo de carga\n",
        "\n",
        "# ===============================================\n",
        "# Passo 3: Carregamento (Load) para o BigQuery\n",
        "# ===============================================\n",
        "\n",
        "# 1. Instalar a biblioteca do BigQuery (se necessário)\n",
        "!pip install --upgrade pandas-gbq google-cloud-bigquery\n",
        "\n",
        "# 2. Autenticação no Google Colab\n",
        "auth.authenticate_user()\n",
        "\n",
        "# 3. Importar a biblioteca do BigQuery e o pandas\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Substitua pelo ID do seu projeto no Google Cloud\n",
        "projeto_id = 'estrutura-de-dados-1'\n",
        "\n",
        "# Criar um cliente BigQuery\n",
        "client = bigquery.Client(project=projeto_id)\n",
        "\n",
        "# 4. Carregar o DataFrame de vendas (superstore) para o BigQuery\n",
        "tabela_destino_superstore = f'{projeto_id}.superstore.superstore_clean_py'\n",
        "\n",
        "df_superstore.to_gbq(\n",
        "    destination_table=tabela_destino_superstore,\n",
        "    project_id=projeto_id,\n",
        "    if_exists='replace'\n",
        ")\n",
        "print(f\"DataFrame de vendas carregado para a tabela: {tabela_destino_superstore}\")\n",
        "\n",
        "\n",
        "# 5. Carregar o DataFrame de concorrentes para o BigQuery (se não estiver vazio)\n",
        "if not df_concorrentes.empty:\n",
        "    tabela_destino_concorrentes = f'{projeto_id}.superstore.dim_concorrentes_py'\n",
        "\n",
        "    df_concorrentes.to_gbq(\n",
        "        destination_table=tabela_destino_concorrentes,\n",
        "        project_id=projeto_id,\n",
        "        if_exists='replace'\n",
        "    )\n",
        "    print(f\"DataFrame de concorrentes carregado para a tabela: {tabela_destino_concorrentes}\")\n",
        "else:\n",
        "    print(\"DataFrame de concorrentes está vazio, não será carregado.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zch39eYVfuXt",
        "outputId": "366c141f-316c-4165-9e5a-c5ef42684f98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame de superstore pronto para o carregamento.\n",
            "DataFrame de concorrentes pronto para o carregamento.\n",
            "Requirement already satisfied: pandas-gbq in /usr/local/lib/python3.11/dist-packages (0.29.2)\n",
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.11/dist-packages (3.35.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pandas-gbq) (75.2.0)\n",
            "Requirement already satisfied: db-dtypes<2.0.0,>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq) (1.4.3)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq) (2.2.2)\n",
            "Requirement already satisfied: pyarrow>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq) (18.1.0)\n",
            "Requirement already satisfied: pydata-google-auth>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq) (1.9.1)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=2.10.2 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq) (2.25.1)\n",
            "Requirement already satisfied: google-auth>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq) (1.2.2)\n",
            "Requirement already satisfied: packaging>=22.0.0 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq) (25.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.32.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.10.2->pandas-gbq) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.10.2->pandas-gbq) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.10.2->pandas-gbq) (1.26.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.13.0->pandas-gbq) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.13.0->pandas-gbq) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.13.0->pandas-gbq) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.7.0->pandas-gbq) (2.0.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-resumable-media<3.0.0,>=2.0.0->google-cloud-bigquery) (1.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->pandas-gbq) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->pandas-gbq) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2025.7.14)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.13.0->pandas-gbq) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.7.0->pandas-gbq) (3.3.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1815890139.py:63: FutureWarning: to_gbq is deprecated and will be removed in a future version. Please use pandas_gbq.to_gbq instead: https://pandas-gbq.readthedocs.io/en/latest/api.html#pandas_gbq.to_gbq\n",
            "  df_superstore.to_gbq(\n",
            "100%|██████████| 1/1 [00:00<00:00, 1723.92it/s]\n",
            "/tmp/ipython-input-1815890139.py:75: FutureWarning: to_gbq is deprecated and will be removed in a future version. Please use pandas_gbq.to_gbq instead: https://pandas-gbq.readthedocs.io/en/latest/api.html#pandas_gbq.to_gbq\n",
            "  df_concorrentes.to_gbq(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame de vendas carregado para a tabela: estrutura-de-dados-1.superstore.superstore_clean_py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 2003.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame de concorrentes carregado para a tabela: estrutura-de-dados-1.superstore.dim_concorrentes_py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# CARREGAMENTO (LOAD) para o BigQuery\n",
        "# ===============================================\n",
        "# A autenticação agora será feita através da variável de ambiente\n",
        "# GOOGLE_APPLICATION_CREDENTIALS. A linha abaixo não é mais necessária.\n",
        "# auth.authenticate_user()\n",
        "\n",
        "# Insira o ID do seu projeto no Google Cloud\n",
        "projeto_id = 'estrutura-de-dados-1'\n",
        "dataset_id = 'superstore'\n",
        "\n",
        "print(\"\\nIniciando o carregamento para o BigQuery...\")\n",
        "\n",
        "if 'fact_sales_df' in locals() and not fact_sales_df.empty:\n",
        "    pandas_gbq.to_gbq(fact_sales_df, f'{projeto_id}.{dataset_id}.fact_sales', project_id=projeto_id, if_exists='replace')\n",
        "    print(\"Tabela fact_sales carregada.\")\n",
        "\n",
        "if 'dim_location_df' in locals() and not dim_location_df.empty:\n",
        "    pandas_gbq.to_gbq(dim_location_df, f'{projeto_id}.{dataset_id}.dim_location', project_id=projeto_id, if_exists='replace')\n",
        "    print(\"Tabela dim_location carregada.\")\n",
        "\n",
        "if 'dim_customer_df' in locals() and not dim_customer_df.empty:\n",
        "    pandas_gbq.to_gbq(dim_customer_df, f'{projeto_id}.{dataset_id}.dim_customer', project_id=projeto_id, if_exists='replace')\n",
        "    print(\"Tabela dim_customer carregada.\")\n",
        "\n",
        "if 'dim_product_df' in locals() and not dim_product_df.empty:\n",
        "    pandas_gbq.to_gbq(dim_product_df, f'{projeto_id}.{dataset_id}.dim_product', project_id=projeto_id, if_exists='replace')\n",
        "    print(\"Tabela dim_product carregada.\")\n",
        "\n",
        "if 'dim_order_df' in locals() and not dim_order_df.empty:\n",
        "    pandas_gbq.to_gbq(dim_order_df, f'{projeto_id}.{dataset_id}.dim_order', project_id=projeto_id, if_exists='replace')\n",
        "    print(\"Tabela dim_order carregada.\")\n",
        "\n",
        "if 'df_concorrentes' in locals() and not df_concorrentes.empty:\n",
        "    pandas_gbq.to_gbq(df_concorrentes, f'{projeto_id}.{dataset_id}.dim_concorrentes', project_id=projeto_id, if_exists='replace')\n",
        "    print(\"Tabela dim_concorrentes carregada.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myr0pVT3Wrzf",
        "outputId": "9acbe552-170b-48d4-c83e-41085d780827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando o carregamento para o BigQuery...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 3761.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tabela fact_sales carregada.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 2639.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tabela dim_location carregada.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 2081.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tabela dim_customer carregada.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 8811.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tabela dim_product carregada.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 4173.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tabela dim_order carregada.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 9597.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tabela dim_concorrentes carregada.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}